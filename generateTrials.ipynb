{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial Generation Implementation\n",
    "## Base file\n",
    "- This file will be generated for every participant, ensuring that everything is truely randomised.\n",
    "- This file then generates the file name of each trial to be played.\n",
    "- It needs to be merged with the general information/database of each stimuli:\n",
    "    - durations (file generated by the `getDurations` Praat script.\n",
    "    - `hasQuestion` + `questionText` from the work done by Marieke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy.random import RandomState\n",
    "from itertools import product\n",
    "\n",
    "######## FUNCTIONS\n",
    "#----------------------\n",
    "def simple_shuffle(frame, block=None, times=10, seed=None, resetInd=False):\n",
    "    prng = RandomState(seed)\n",
    "    \n",
    "    def _shuffle(chunk):\n",
    "        for _ in range(times):\n",
    "            chunk = chunk.reindex(prng.permutation(chunk.index))\n",
    "        if resetInd is True:\n",
    "            chunk=chunk.reset_index(drop=True)\n",
    "        return chunk\n",
    "    \n",
    "    if block is None:\n",
    "        return _shuffle(frame)\n",
    "    else:\n",
    "        return frame.groupby(block).apply(_shuffle)\n",
    "    \n",
    "def add_blocks(frame, size, name='block', condList=None, id_col=None, start_at=0):\n",
    "\n",
    "    def _assigner(lim,size):\n",
    "        num = 0\n",
    "        n=0\n",
    "        while n<=lim:\n",
    "            if n % size == 0 and n != 0:\n",
    "                num +=1\n",
    "                n += 1\n",
    "                #print blocks[num],n, num\n",
    "                yield blocks[num]\n",
    "            else:\n",
    "                n +=1\n",
    "                #print blocks[num],n,num\n",
    "                yield blocks[num]\n",
    "\n",
    "    if condList is None:\n",
    "        blocks=range(len(frame)/size)\n",
    "    else:\n",
    "        blocks=condList\n",
    "    \n",
    "    assigner=_assigner(len(frame),size)\n",
    "\n",
    "    def _add(chunk):\n",
    "        chunk[name]=[assigner.next() for _ in xrange(len(chunk))]\n",
    "        return chunk\n",
    "    \n",
    "    if id_col is None:\n",
    "        new_frame=_add(frame).sort_values(by=name)\n",
    "    else:\n",
    "        new_frame=frame.groupby(id_col).apply(_add).sort_values(by=id_col)\n",
    "\n",
    "    if condList is None:\n",
    "        #new_frame[name]=new_frame[name]+start_at\n",
    "        return new_frame\n",
    "    else:\n",
    "        new_frame[name]=new_frame[name]\n",
    "        return new_frame\n",
    "\n",
    "def genTr(frame,firstBlockSize, secondBlockSize, firstBlockName, secondBlockName,seedOfShuffle=None):\n",
    "    #df=simple_shuffle(df)\n",
    "    rel=add_blocks(frame,firstBlockSize,name=firstBlockName,condList=['related','unrelated'])\n",
    "    speak=add_blocks(rel,secondBlockSize,name=secondBlockName,condList=['native','nonNative','native','nonNative'])\n",
    "    speak.sort_values(by=firstBlockName)\n",
    "    \n",
    "    return speak\n",
    "\n",
    "######## IMPLEMENTATIONS\n",
    "#-------------------------   \n",
    "\n",
    "df=pd.DataFrame({'sentID':xrange(1,121)})\n",
    "rel=add_blocks(df,60,name='relatedness',condList=['related','unrelated'])\n",
    "speak=add_blocks(df,30,name='speaker',condList=['Nat','nonNat','Nat','nonNat'])\n",
    "speak=speak[['speaker','sentID','relatedness']]\n",
    "##speak['ext']=\".wav\"\n",
    "speak['filename']=speak.apply(lambda x: '_'.join(x.dropna().astype(str).values),axis=1)\n",
    "speak=speak.sort_values(by=\"relatedness\")\n",
    "final=simple_shuffle(speak)\n",
    "#final.to_csv('testGen.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>sentID</th>\n",
       "      <th>relatedness</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>nonNat</td>\n",
       "      <td>96</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>nonNat_96_unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Nat</td>\n",
       "      <td>68</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>Nat_68_unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Nat</td>\n",
       "      <td>74</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>Nat_74_unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>nonNat</td>\n",
       "      <td>54</td>\n",
       "      <td>related</td>\n",
       "      <td>nonNat_54_related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>nonNat</td>\n",
       "      <td>36</td>\n",
       "      <td>related</td>\n",
       "      <td>nonNat_36_related</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   speaker  sentID relatedness             filename\n",
       "95  nonNat      96   unrelated  nonNat_96_unrelated\n",
       "67     Nat      68   unrelated     Nat_68_unrelated\n",
       "73     Nat      74   unrelated     Nat_74_unrelated\n",
       "53  nonNat      54     related    nonNat_54_related\n",
       "35  nonNat      36     related    nonNat_36_related"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dbase=pd.read_table('./stimDatabase/allAbove70.txt',encoding='utf-16')\n",
    "df=dbase['sentID']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dbase['sentID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trim Database to 120\n",
    "- A length of 126 is gonna cause all sorts of problems, so here are the sentence I'll cut down\n",
    "- Sentences were cut down simply by taking the ones with the lowest close ratings we had in the database.\n",
    "### Eliminated sentences\n",
    "1. 70\n",
    "2. 105\n",
    "3. 53\n",
    "4. 113\n",
    "5. 36\n",
    "6. 117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "excludedSents=[70,105,53,113,36,117]\n",
    "#sub=dbase[dbase['sentID'] not in excludedSents]\n",
    "\n",
    "sub=dbase.query('sentID not in [70,105,53,113,36,117]')\n",
    "sub.to_csv('./stimDatabase/120allAbove70.csv',encoding='utf-16',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GenTrials Based on sentIDs from Dbase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "dbase=pd.read_csv('./stimDatabase/120allAbove70.csv',encoding='utf-16')\n",
    "df=pd.DataFrame({'sentID':dbase['sentID']})\n",
    "rel=add_blocks(df,60,name='relatedness',condList=['related','unrelated'])\n",
    "speak=add_blocks(df,30,name='speaker',condList=['Nat','nonNat','Nat','nonNat'])\n",
    "speak=speak[['speaker','sentID','relatedness']]\n",
    "speak['filename']=speak.apply(lambda x: '_'.join(x.dropna().astype(str).values),axis=1)\n",
    "speak=speak.sort_values(by=\"relatedness\")\n",
    "final=simple_shuffle(speak).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#practSents=pd.read_table('./stimDatabase/allAbove70.txt',encoding='utf-16')\n",
    "#practSents=practSents.query('sentID in [70,105,53,113,36,117]')\n",
    "#practSents.to_csv('./stimDatabase/practSents.csv',encoding='utf-16',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>sentID</th>\n",
       "      <th>relatedness</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nat</td>\n",
       "      <td>16</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>Nat_16_unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nonNat</td>\n",
       "      <td>79</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>nonNat_79_unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nonNat</td>\n",
       "      <td>133</td>\n",
       "      <td>related</td>\n",
       "      <td>nonNat_133_related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nat</td>\n",
       "      <td>129</td>\n",
       "      <td>related</td>\n",
       "      <td>Nat_129_related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nonNat</td>\n",
       "      <td>98</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>nonNat_98_unrelated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  speaker  sentID relatedness             filename\n",
       "0     Nat      16   unrelated     Nat_16_unrelated\n",
       "1  nonNat      79   unrelated  nonNat_79_unrelated\n",
       "2  nonNat     133     related   nonNat_133_related\n",
       "3     Nat     129     related      Nat_129_related\n",
       "4  nonNat      98   unrelated  nonNat_98_unrelated"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge genned file with info from dbase\n",
    "- hasQuestion\n",
    "- Question\n",
    "- yesOrNo\n",
    "\n",
    "**NOTE:** Durations will need to be pulled from the database generated by the `getDurations` praat script. (or feed into the general database first. For now this is not a priority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dBaseToMerge=dbase[['sentID','hasQuestion','Question','yesOrNo']]\n",
    "#####ATTENTION CHANGE THIS TO THE ACTUAL DURATION FILES\n",
    "durations=pd.DataFrame({'sentID':final.sentID,'duration':np.random.randint(0,5,120)}) \n",
    "######\n",
    "hasQmerge=pd.merge(final,toMerge,how='left',on='sentID')\n",
    "allMerge=pd.merge(hasQmerge,durations,how='left',on='sentID')\n",
    "allMerge['part']='experiment'\n",
    "###### DON'T FORGET TO ADD AS MANY COLUMNS TO PRACTSENTS AS THERE\n",
    "######ARE IN THE FINAL DURATION FILE\n",
    "\n",
    "#### ALSO MATCHING WILL HAVE TO BE DONE ON **FILENAME** SINCE DURATIONS ARE DIFFERENT FOR EACH FILE!\n",
    "practSents=pd.read_csv('./stimDatabase/practSents.csv',encoding='utf-16',sep='\\t')\n",
    "##########\n",
    "finalTrials=pd.concat([allMerge,practSents])\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 4,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
